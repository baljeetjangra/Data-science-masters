{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans - ANOVA (Analysis of Variance) is a statistical method used to analyze the differences between means of two or more groups. However, ANOVA has several assumptions that must be met for the results to be valid. The following are the assumptions required for ANOVA:\n",
    "\n",
    "Independence: Observations within and between groups should be independent. Each subject should only be in one group, and each group should not influence the other groups. Violation of this assumption may lead to a biased estimate of the variance, leading to inaccurate results.\n",
    "\n",
    "Normality: The residuals of each group should be normally distributed. Normality assumes that the distribution of errors is symmetric, and the mean of the distribution is zero. If the data is not normally distributed, it could lead to inaccurate results.\n",
    "\n",
    "Homogeneity of variance: Homogeneity of variance refers to the assumption that the variance of the residuals is equal across all groups. If the variance of the residuals is unequal, it could lead to inaccurate results.\n",
    "\n",
    "Examples of violations that could impact the validity of ANOVA results include:\n",
    "\n",
    "Outliers: Outliers can cause a violation of the normality assumption by skewing the distribution of the data. Outliers may also cause unequal variance, which violates the homogeneity of variance assumption.\n",
    "\n",
    "Non-normality: If the residuals are not normally distributed, it can cause inaccurate results, especially with small sample sizes.\n",
    "\n",
    "Unequal variance: Unequal variance can cause inaccurate results, especially with small sample sizes.\n",
    "\n",
    "Non-independence: If observations within or between groups are not independent, it can lead to biased estimates of variance and inaccurate results.\n",
    "\n",
    "Non-random sampling: If the sample is not representative of the population, it can lead to inaccurate results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans - The three types of ANOVA are:\n",
    "\n",
    "One-Way ANOVA: This is used when there is only one factor being tested, and it has two or more levels. For example, a researcher might use one-way ANOVA to test whether there is a significant difference in the mean weight of plants grown under different fertilizer treatments.\n",
    "\n",
    "Two-Way ANOVA: This is used when there are two factors being tested, and each factor has two or more levels. For example, a researcher might use two-way ANOVA to test whether there is a significant difference in the mean weight of plants grown under different fertilizer treatments and different light levels.\n",
    "\n",
    "N-Way ANOVA: This is used when there are more than two factors being tested, and each factor has two or more levels. For example, a researcher might use n-way ANOVA to test whether there is a significant difference in the mean weight of plants grown under different fertilizer treatments, light levels, and watering schedules."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans - The partitioning of variance in ANOVA refers to the division of the total variance observed in a dataset into different components that can be attributed to different sources. There are two main sources of variance in ANOVA: the variability within groups and the variability between groups.\n",
    "\n",
    "By partitioning the total variance into these components, ANOVA can determine whether the differences observed between groups are statistically significant, or whether they can be attributed to chance. This is important because it allows researchers to determine whether a treatment or intervention has a significant effect, or whether any observed differences could be due to random chance.\n",
    "\n",
    "Understanding the partitioning of variance is also important for interpreting the results of ANOVA. By identifying the proportion of variance that can be attributed to different sources, researchers can gain insight into the relative importance of different factors in the outcome being studied. Additionally, understanding the partitioning of variance can help researchers identify potential sources of error or bias in their study design or analysis.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 151.33333333333331\n",
      "SSE: 151.33333333333317\n",
      "SSR: 6.310887241768094e-29\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a sample dataset with a categorical variable and a continuous variable\n",
    "df = pd.DataFrame({'group': ['A', 'B', 'C', 'D', 'E', 'F'],\n",
    "                   'score': [10, 15, 20, 12, 18, 25]})\n",
    "\n",
    "# Fit a one-way ANOVA model\n",
    "model = ols('score ~ group', data=df).fit()\n",
    "\n",
    "# Calculate the total sum of squares (SST)\n",
    "sst = sum((df['score'] - df['score'].mean()) ** 2)\n",
    "\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "sse = sum((model.predict(df) - df['score'].mean()) ** 2)\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "ssr = sum((df['score'] - model.predict(df)) ** 2)\n",
    "\n",
    "print('SST:', sst)\n",
    "print('SSE:', sse)\n",
    "print('SSR:', ssr)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                sum_sq     df         F    PR(>F)\n",
      "sex         231.460310    1.0  3.022685  0.083390\n",
      "time        473.011803    1.0  6.177153  0.013623\n",
      "sex:time      3.371906    1.0  0.044034  0.833968\n",
      "Residual  18377.855945  240.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Load the tips dataset from seaborn\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "\n",
    "# Create a formula for the ANOVA model\n",
    "formula = 'total_bill ~ sex + time + sex:time'\n",
    "\n",
    "# Fit the ANOVA model\n",
    "model = ols(formula, data=tips).fit()\n",
    "\n",
    "# Perform the ANOVA and print the results table\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans - If we obtained an F-statistic of 5.23 and a p-value of 0.02, we can conclude that there is evidence of a significant difference between the groups. In other words, the means of the groups are not all equal.\n",
    "\n",
    "The F-statistic indicates the ratio of the variance between groups to the variance within groups. A larger F-statistic indicates a larger difference between group means relative to the variation within groups. In this case, an F-statistic of 5.23 suggests that the differences between the groups are larger than what would be expected due to chance variation alone.\n",
    "\n",
    "The p-value of 0.02 indicates that the probability of observing such a large F-statistic if the group means are all equal is only 2%. Therefore, we reject the null hypothesis of equal group means and conclude that at least one of the group means is different from the others."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans - Handling missing data in a repeated measures ANOVA can be challenging, as the data is often dependent and the same individuals are measured across multiple time points or conditions. There are different methods to handle missing data, including:\n",
    "\n",
    "Listwise deletion: This method involves excluding all individuals who have missing data on any of the variables. While this method is straightforward, it can lead to a reduction in sample size and loss of statistical power.\n",
    "\n",
    "Mean imputation: This method involves replacing missing values with the mean value for that variable. While this method is easy to implement, it can lead to biased estimates of the means and variances.\n",
    "\n",
    "Maximum likelihood estimation: This method involves using statistical models to estimate the missing values based on the available data. This method can provide unbiased estimates of the means and variances, but it requires a sophisticated statistical model and may not work well for small sample sizes.\n",
    "\n",
    "The consequences of using different methods to handle missing data can vary depending on the amount and pattern of missing data, as well as the method used. In general, using listwise deletion can lead to a reduction in statistical power, while mean imputation can lead to biased estimates of the means and variances. Maximum likelihood estimation can provide unbiased estimates of the means and variances, but it may not work well for small sample sizes or when the missing data is not missing at random. It is important to carefully consider the amount and pattern of missing data and choose a method that is appropriate for the specific research question and data at hand."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans - Post-hoc tests are used to determine which groups differ significantly from each other after obtaining a significant result from an ANOVA. Some common post-hoc tests include Tukey's HSD, Bonferroni correction, Scheffé's method, and Dunnett's test.\n",
    "\n",
    "Tukey's HSD: This test is used to compare all possible pairs of groups to determine which pairs have a significant difference. It controls the family-wise error rate (FWER), which is the probability of making at least one type I error among all the comparisons. Tukey's HSD is commonly used when there are equal sample sizes and variances across all groups.\n",
    "\n",
    "Bonferroni correction: This test is used to control the FWER by dividing the significance level by the number of pairwise comparisons. For example, if there are four groups, and the significance level is set to 0.05, then the adjusted significance level would be 0.05/6 = 0.0083, since there are six pairwise comparisons. Bonferroni correction is a conservative method, and it is commonly used when there are unequal sample sizes or variances across groups.\n",
    "\n",
    "Scheffé's method: This test is also used to control the FWER, but it is less conservative than Bonferroni correction. It is commonly used when there are unequal sample sizes or variances across groups.\n",
    "Dunnett's test: This test is used to compare each group to a control group. It controls the family-wise error rate for these comparisons.\n",
    "An example of a situation where a post-hoc test might be necessary is in a study comparing the effectiveness of three different types of pain medication. An ANOVA might reveal a significant difference between the groups, but a post-hoc test would be necessary to determine which specific pairs of groups differ significantly from each other.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans - To conduct a one-way ANOVA in Python to compare the mean weight loss of three diets, we can use the scipy.stats module. Let's assume that the weight loss data is stored in a Pandas DataFrame called df, where the column 'diet' specifies the diet group (A, B, or C), and the column 'weight_loss' specifies the weight loss in pounds. Here's the Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                sum_sq     df         F    PR(>F)\n",
      "diet        198.281750    2.0  1.253553  0.287343\n",
      "Residual  19060.182333  241.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('tips')\n",
    "import random\n",
    "\n",
    "random.seed(123) # set seed for reproducibility\n",
    "\n",
    "diet = []\n",
    "for i in range(len(df)):\n",
    "    diet.append(random.choice(['A', 'B', 'C']))\n",
    "\n",
    "df['diet'] = diet\n",
    "model = sm.formula.ols('total_bill ~ diet', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "print(anova_table)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Data example :\n",
      "  Software Experience       Time\n",
      "0        A     Novice  12.828739\n",
      "1        A     Novice  16.994691\n",
      "2        A     Novice  15.565957\n",
      "3        A     Novice  11.987411\n",
      "4        A     Novice  13.842799\n",
      "\n",
      "======================================================================================\n",
      "\n",
      "                             df      sum_sq     mean_sq          F  \\\n",
      "C(Software)                 2.0  204.881181  102.440590  18.135666   \n",
      "C(Experience)               1.0  165.079097  165.079097  29.224933   \n",
      "C(Software):C(Experience)   2.0   17.481552    8.740776   1.547431   \n",
      "Residual                   56.0  316.319953    5.648571        NaN   \n",
      "\n",
      "                                 PR(>F)  \n",
      "C(Software)                8.460472e-07  \n",
      "C(Experience)              1.375177e-06  \n",
      "C(Software):C(Experience)  2.217544e-01  \n",
      "Residual                            NaN  \n",
      "\n",
      "\n",
      "Conclusion: There is a significant main effect of software.\n",
      "Conclusion: There is a significant main effect of experience.\n",
      "Conclusion: There is no significant interaction effect between software and experience.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import numpy as np\n",
    "\n",
    "# Setting random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# Generating 2 random time samples for novice and expert\n",
    "time_novice = np.random.normal(loc=15, scale=2, size=30)\n",
    "time_expert = np.random.normal(loc=10, scale=2, size=30)\n",
    "\n",
    "# Generate simulated data\n",
    "data = pd.DataFrame({\n",
    "    'Software': ['A']*20 + ['B']*20 + ['C']*20,\n",
    "    'Experience': ['Novice']*30 + ['Experienced']*30,\n",
    "    'Time': list(time_novice)+list(time_expert)\n",
    "})\n",
    "\n",
    "# Print the simulated data head \n",
    "print('Simulated Data example :')\n",
    "print(data.head())\n",
    "\n",
    "print('\\n======================================================================================\\n')\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=data).fit()\n",
    "table = sm.stats.anova_lm(model, typ=1)\n",
    "\n",
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Main effects and interaction effect\n",
    "print(table)\n",
    "print('\\n')\n",
    "if table['PR(>F)'][0] < alpha:\n",
    "    print(\"Conclusion: There is a significant main effect of software.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no significant main effect of software.\")\n",
    "\n",
    "if table['PR(>F)'][1] < alpha:\n",
    "    print(\"Conclusion: There is a significant main effect of experience.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no significant main effect of experience.\")\n",
    "\n",
    "if table['PR(>F)'][2] < alpha:\n",
    "    print(\"Conclusion: There is a significant interaction effect between software and experience.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no significant interaction effect between software and experience.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the interpretations of the three conclusions:\n",
    "\"There is a significant main effect of software\": This means that the software programs used by the employees have a significant impact on the outcome variable (e.g., completion time), independent of the experience level of the employees. This suggests that the choice of software program is an important factor that should be considered carefully when completing this task.\n",
    "\n",
    "\"There is a significant main effect of experience\": This means that the experience level of the employees has a significant impact on the outcome variable, independent of the software program used. Specifically, this suggests that experienced employees may complete the task faster than novices, or vice versa. This finding can be helpful for the company to identify the best employees for a given task and to provide appropriate training for new employees.\n",
    "\n",
    "\"There is NO significant interaction effect between software and experience\": This means that the effect of software on the outcome variable does not depend on the experience level of the employees, and vice versa. This suggests that the software programs perform similarly for both novices and experienced employees. This finding can be helpful for the company to decide which software program to use, as they do not need to consider the experience level of the employees when making the choice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -3.0651400307444217\n",
      "p-value: 0.0024791276971826066\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj  lower  upper  reject\n",
      "---------------------------------------------------------\n",
      "control experimental   4.2465 0.0025 1.5144 6.9786   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# generate sample data\n",
    "control_scores = np.random.normal(70, 10, 100)\n",
    "experimental_scores = np.random.normal(75, 10, 100)\n",
    "\n",
    "# conduct two-sample t-test\n",
    "t_statistic, p_value = ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# print results\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# conduct post-hoc test (Tukey's HSD)\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "tukey_results = pairwise_tukeyhsd(np.concatenate((control_scores, experimental_scores)),\n",
    "                                  np.concatenate((np.repeat('control', 100), np.repeat('experimental', 100))))\n",
    "\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we generate two samples of test scores (one for the control group and one for the experimental group) using the numpy.random.normal function. We then conduct a two-sample t-test using scipy.stats.ttest_ind, which returns the t-statistic and p-value. If the p-value is less than our chosen significance level (e.g., 0.05), we conclude that there is a significant difference in test scores between the two groups.\n",
    "\n",
    "In this case, let's say the t-statistic is 2.24 and the p-value is 0.027. This indicates that there is a significant difference in test scores between the two groups (since the p-value is less than 0.05). To determine which group(s) differ significantly from each other, we can conduct a post-hoc test using Tukey's HSD (using the statsmodels.stats.multicomp.pairwise_tukeyhsd function). This will give us a table of results showing the pairwise differences in means and the corresponding p-values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Source  ddof1  ddof2         F     p-unc      ng2       eps\n",
      "0  store      2     58  1.669709  0.197225  0.03671  0.959348\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pingouin as pg\n",
    "\n",
    "# create a sample dataset\n",
    "np.random.seed(123)\n",
    "data = pd.DataFrame({\n",
    "    'day': np.repeat(range(1, 31), 3),\n",
    "    'store': np.tile(['A', 'B', 'C'], 30),\n",
    "    'sales': np.random.normal(loc=1000, scale=100, size=90)\n",
    "})\n",
    "\n",
    "# conduct repeated measures ANOVA\n",
    "rm_anova = pg.rm_anova(dv='sales', within='store', subject='day', data=data)\n",
    "print(rm_anova)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Contrast  A  B  Paired  Parametric         T   dof alternative     p-unc  \\\n",
      "0    store  A  B    True        True -1.740227  29.0   two-sided  0.092423   \n",
      "1    store  A  C    True        True -0.892032  29.0   two-sided  0.379718   \n",
      "2    store  B  C    True        True  0.998930  29.0   two-sided  0.326091   \n",
      "\n",
      "     p-corr p-adjust   BF10    hedges  \n",
      "0  0.277268     bonf  0.742 -0.453587  \n",
      "1  1.000000     bonf   0.28 -0.256064  \n",
      "2  0.978273     bonf  0.307  0.216494  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Baljeet\\anaconda3\\envs\\data_env\\lib\\site-packages\\pingouin\\pairwise.py:28: UserWarning: pairwise_ttests is deprecated, use pairwise_tests instead.\n",
      "  warnings.warn(\"pairwise_ttests is deprecated, use pairwise_tests instead.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# conduct pairwise t-test with Bonferroni correction\n",
    "posthoc = pg.pairwise_ttests(dv='sales', within='store', subject='day', data=data, padjust='bonf')\n",
    "print(posthoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
